Found 1801 images belonging to 2 classes.
Found 2000 images belonging to 2 classes.
WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5
    8192/58889256 [..............................] - ETA: 1:27  507904/58889256 [..............................] - ETA: 7s   5259264/58889256 [=>............................] - ETA: 1s12009472/58889256 [=====>........................] - ETA: 0s19128320/58889256 [========>.....................] - ETA: 0s26804224/58889256 [============>.................] - ETA: 0s32374784/58889256 [===============>..............] - ETA: 0s36831232/58889256 [=================>............] - ETA: 0s43409408/58889256 [=====================>........] - ETA: 0s50536448/58889256 [========================>.....] - ETA: 0s55566336/58889256 [===========================>..] - ETA: 0s58892288/58889256 [==============================] - 1s 0us/step
2019-06-16 11:20:25.983423: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-06-16 11:20:25.990993: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2019-06-16 11:20:25.991665: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x56525c76b6b0 executing computations on platform Host. Devices:
2019-06-16 11:20:25.991733: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-06-16 11:20:26.087470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-16 11:20:26.089212: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x56525c755d90 executing computations on platform CUDA. Devices:
2019-06-16 11:20:26.089256: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-06-16 11:20:26.089500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:05.0
totalMemory: 11.17GiB freeMemory: 11.11GiB
2019-06-16 11:20:26.089555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-06-16 11:20:26.091327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-16 11:20:26.091397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-06-16 11:20:26.091420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-06-16 11:20:26.091775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:05.0, compute capability: 3.7)
Predicting bottleneck training features
Predicting bottleneck validation features
WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Train on 200 samples, validate on 1000 samples
Epoch 1/50
2019-06-16 11:20:58.398188: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
 40/200 [=====>........................] - ETA: 2s - loss: 3.4252 - acc: 0.6500200/200 [==============================] - 1s 4ms/step - loss: 3.7963 - acc: 0.7300 - val_loss: 1.1576 - val_acc: 0.9220
Epoch 2/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.8062 - acc: 0.8750200/200 [==============================] - 0s 836us/step - loss: 2.4715 - acc: 0.8400 - val_loss: 5.7314 - val_acc: 0.6330
Epoch 3/50
 40/200 [=====>........................] - ETA: 0s - loss: 6.7755 - acc: 0.5750200/200 [==============================] - 0s 827us/step - loss: 4.7866 - acc: 0.6950 - val_loss: 1.1578 - val_acc: 0.9220
Epoch 4/50
 40/200 [=====>........................] - ETA: 0s - loss: 0.6951 - acc: 0.9500200/200 [==============================] - 0s 748us/step - loss: 1.3493 - acc: 0.9050 - val_loss: 0.8797 - val_acc: 0.9380
Epoch 5/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.6030 - acc: 0.9000200/200 [==============================] - 0s 811us/step - loss: 1.7320 - acc: 0.8850 - val_loss: 2.2075 - val_acc: 0.8560
Epoch 6/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.1957 - acc: 0.9250200/200 [==============================] - 0s 831us/step - loss: 1.4150 - acc: 0.9100 - val_loss: 0.9571 - val_acc: 0.9350
Epoch 7/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.6030 - acc: 0.9000200/200 [==============================] - 0s 834us/step - loss: 1.1236 - acc: 0.9250 - val_loss: 1.3215 - val_acc: 0.9150
Epoch 8/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.2089 - acc: 0.9250200/200 [==============================] - 0s 830us/step - loss: 0.6105 - acc: 0.9600 - val_loss: 0.8276 - val_acc: 0.9450
Epoch 9/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.2001 - acc: 0.9250200/200 [==============================] - 0s 833us/step - loss: 0.6954 - acc: 0.9550 - val_loss: 0.8946 - val_acc: 0.9420
Epoch 10/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.1957 - acc: 0.9250200/200 [==============================] - 0s 835us/step - loss: 0.7297 - acc: 0.9500 - val_loss: 1.9508 - val_acc: 0.8750
Epoch 11/50
 40/200 [=====>........................] - ETA: 0s - loss: 0.8059 - acc: 0.9500160/200 [=======================>......] - ETA: 0s - loss: 0.7052 - acc: 0.9562200/200 [==============================] - 0s 1ms/step - loss: 0.8865 - acc: 0.9450 - val_loss: 1.9508 - val_acc: 0.8750
Epoch 12/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.1057e-07 - acc: 1.0000200/200 [==============================] - 0s 850us/step - loss: 0.2003 - acc: 0.9850 - val_loss: 0.8199 - val_acc: 0.9480
Epoch 13/50
 40/200 [=====>........................] - ETA: 0s - loss: 0.8015 - acc: 0.9500200/200 [==============================] - 0s 1ms/step - loss: 0.3215 - acc: 0.9800 - val_loss: 0.7031 - val_acc: 0.9480
Epoch 14/50
 40/200 [=====>........................] - ETA: 0s - loss: 0.4030 - acc: 0.9750200/200 [==============================] - 0s 865us/step - loss: 0.7922 - acc: 0.9500 - val_loss: 1.8112 - val_acc: 0.8840
Epoch 15/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.6188 - acc: 0.8750200/200 [==============================] - 0s 854us/step - loss: 0.6595 - acc: 0.9500 - val_loss: 0.7397 - val_acc: 0.9520
Epoch 16/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.0720e-07 - acc: 1.0000200/200 [==============================] - 0s 846us/step - loss: 0.4021 - acc: 0.9750 - val_loss: 0.7397 - val_acc: 0.9520
Epoch 17/50
 40/200 [=====>........................] - ETA: 0s - loss: 0.8015 - acc: 0.9500200/200 [==============================] - 0s 824us/step - loss: 0.2400 - acc: 0.9850 - val_loss: 0.7397 - val_acc: 0.9520
Epoch 18/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.0816e-07 - acc: 1.0000200/200 [==============================] - 0s 836us/step - loss: 0.2400 - acc: 0.9850 - val_loss: 0.7386 - val_acc: 0.9520
Epoch 19/50
 40/200 [=====>........................] - ETA: 0s - loss: 0.4030 - acc: 0.9750200/200 [==============================] - 0s 820us/step - loss: 0.2283 - acc: 0.9850 - val_loss: 2.0507 - val_acc: 0.8670
Epoch 20/50
 40/200 [=====>........................] - ETA: 0s - loss: 0.4030 - acc: 0.9750200/200 [==============================] - 0s 868us/step - loss: 0.7253 - acc: 0.9550 - val_loss: 2.0507 - val_acc: 0.8670
Epoch 21/50
 40/200 [=====>........................] - ETA: 0s - loss: 0.4030 - acc: 0.9750200/200 [==============================] - 0s 893us/step - loss: 0.9921 - acc: 0.9350 - val_loss: 0.6064 - val_acc: 0.9580
Epoch 22/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.0816e-07 - acc: 1.0000200/200 [==============================] - 0s 841us/step - loss: 0.5457 - acc: 0.9650 - val_loss: 1.3340 - val_acc: 0.9160
Epoch 23/50
 40/200 [=====>........................] - ETA: 0s - loss: 0.4030 - acc: 0.9750200/200 [==============================] - 0s 890us/step - loss: 0.5633 - acc: 0.9650 - val_loss: 1.3340 - val_acc: 0.9160
Epoch 24/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.4192 - acc: 0.9000200/200 [==============================] - 0s 928us/step - loss: 0.3636 - acc: 0.9750 - val_loss: 0.5454 - val_acc: 0.9630
Epoch 25/50
 40/200 [=====>........................] - ETA: 0s - loss: 0.5281 - acc: 0.9500200/200 [==============================] - 0s 923us/step - loss: 0.5839 - acc: 0.9600 - val_loss: 1.0390 - val_acc: 0.9300
Epoch 26/50
 40/200 [=====>........................] - ETA: 0s - loss: 0.3986 - acc: 0.9750200/200 [==============================] - 0s 963us/step - loss: 0.4392 - acc: 0.9700 - val_loss: 0.5912 - val_acc: 0.9630
Epoch 27/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.0864e-07 - acc: 1.0000200/200 [==============================] - 0s 1ms/step - loss: 0.1952 - acc: 0.9850 - val_loss: 0.9065 - val_acc: 0.9430
Epoch 28/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.1008e-07 - acc: 1.0000200/200 [==============================] - 0s 915us/step - loss: 0.0822 - acc: 0.9950 - val_loss: 0.5277 - val_acc: 0.9640
Epoch 29/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.0864e-07 - acc: 1.0000200/200 [==============================] - 0s 1ms/step - loss: 0.0495 - acc: 0.9950 - val_loss: 0.5149 - val_acc: 0.9650
Epoch 30/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.0864e-07 - acc: 1.0000200/200 [==============================] - 0s 833us/step - loss: 0.0797 - acc: 0.9950 - val_loss: 0.5149 - val_acc: 0.9650
Epoch 31/50
 40/200 [=====>........................] - ETA: 0s - loss: 0.3986 - acc: 0.9750200/200 [==============================] - 0s 889us/step - loss: 0.1677 - acc: 0.9850 - val_loss: 0.6469 - val_acc: 0.9570
Epoch 32/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.0912e-07 - acc: 1.0000200/200 [==============================] - 0s 958us/step - loss: 1.0893e-07 - acc: 1.0000 - val_loss: 0.6469 - val_acc: 0.9570
Epoch 33/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.2499e-07 - acc: 1.0000200/200 [==============================] - 0s 973us/step - loss: 1.1191e-07 - acc: 1.0000 - val_loss: 0.6454 - val_acc: 0.9580
Epoch 34/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.0912e-07 - acc: 1.0000200/200 [==============================] - 0s 970us/step - loss: 1.0923e-07 - acc: 1.0000 - val_loss: 0.6449 - val_acc: 0.9580
Epoch 35/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.1057e-07 - acc: 1.0000200/200 [==============================] - 0s 976us/step - loss: 1.0893e-07 - acc: 1.0000 - val_loss: 0.6449 - val_acc: 0.9580
Epoch 36/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.0912e-07 - acc: 1.0000200/200 [==============================] - 0s 984us/step - loss: 0.0174 - acc: 0.9950 - val_loss: 0.7714 - val_acc: 0.9490
Epoch 37/50
 40/200 [=====>........................] - ETA: 0s - loss: 0.3986 - acc: 0.9750200/200 [==============================] - 0s 909us/step - loss: 0.2372 - acc: 0.9850 - val_loss: 0.8853 - val_acc: 0.9440
Epoch 38/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.1008e-07 - acc: 1.0000200/200 [==============================] - 0s 945us/step - loss: 0.0806 - acc: 0.9950 - val_loss: 0.8853 - val_acc: 0.9440
Epoch 39/50
 40/200 [=====>........................] - ETA: 0s - loss: 0.4030 - acc: 0.9750200/200 [==============================] - 0s 872us/step - loss: 0.2418 - acc: 0.9850 - val_loss: 0.8853 - val_acc: 0.9440
Epoch 40/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.0864e-07 - acc: 1.0000200/200 [==============================] - 0s 929us/step - loss: 1.0893e-07 - acc: 1.0000 - val_loss: 0.8853 - val_acc: 0.9440
Epoch 41/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.1201e-07 - acc: 1.0000200/200 [==============================] - 0s 943us/step - loss: 3.3332e-05 - acc: 1.0000 - val_loss: 0.6241 - val_acc: 0.9600
Epoch 42/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.1057e-07 - acc: 1.0000200/200 [==============================] - 0s 857us/step - loss: 1.1489e-07 - acc: 1.0000 - val_loss: 0.6159 - val_acc: 0.9610
Epoch 43/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.0864e-07 - acc: 1.0000200/200 [==============================] - 0s 894us/step - loss: 1.0893e-07 - acc: 1.0000 - val_loss: 0.6159 - val_acc: 0.9610
Epoch 44/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.0864e-07 - acc: 1.0000200/200 [==============================] - 0s 899us/step - loss: 1.0893e-07 - acc: 1.0000 - val_loss: 0.6159 - val_acc: 0.9610
Epoch 45/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.0720e-07 - acc: 1.0000200/200 [==============================] - 0s 945us/step - loss: 1.0893e-07 - acc: 1.0000 - val_loss: 0.6159 - val_acc: 0.9610
Epoch 46/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.1153e-07 - acc: 1.0000200/200 [==============================] - 0s 895us/step - loss: 1.0893e-07 - acc: 1.0000 - val_loss: 0.6159 - val_acc: 0.9610
Epoch 47/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.1008e-07 - acc: 1.0000200/200 [==============================] - 0s 855us/step - loss: 1.0893e-07 - acc: 1.0000 - val_loss: 0.6159 - val_acc: 0.9610
Epoch 48/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.1008e-07 - acc: 1.0000200/200 [==============================] - 0s 990us/step - loss: 1.0893e-07 - acc: 1.0000 - val_loss: 0.6159 - val_acc: 0.9610
Epoch 49/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.0768e-07 - acc: 1.0000200/200 [==============================] - 0s 847us/step - loss: 1.0893e-07 - acc: 1.0000 - val_loss: 0.6159 - val_acc: 0.9610
Epoch 50/50
 40/200 [=====>........................] - ETA: 0s - loss: 1.0912e-07 - acc: 1.0000200/200 [==============================] - 0s 950us/step - loss: 1.0893e-07 - acc: 1.0000 - val_loss: 0.6159 - val_acc: 0.9610
